{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image # For face recognition we will the the LBPH Face Recognizer\n",
    "import pickle\n",
    "from tkinter import *\n",
    "from tkinter import ttk  \n",
    "import tkinter as tk\n",
    "import tkinter.messagebox\n",
    "from PIL import Image\n",
    "import win32com.client as win\n",
    "#from sklearn.datasets import fetch_lfw_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detect + take pic\n",
    "def new_user():\n",
    "    image_path = 'Data/images/'\n",
    "    face_cascade = cv2.CascadeClassifier('data/haarcascade/haarcascade_frontalface_default.xml')\n",
    "    # Initializing the face detector and facial landmark predictor \n",
    "    #detector = dlib.get_frontal_face_detector()\n",
    "    #predictor = dlib.shape_predictor(\"data/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(3, 1024) # set video widht\n",
    "    cap.set(4, 720)\n",
    "    name = input('enter user :')\n",
    "    count = 0\n",
    "    id_rand = random.sample(range(1,10000),1)\n",
    "    myList = os.listdir(image_path)\n",
    "\n",
    "    for line in myList:\n",
    "        Type = line.split(\".\")\n",
    "        split = os.path.splitext(line)\n",
    "        if len(Type) > 2:\n",
    "            y = Type[1]\n",
    "        elif len(split) >= 2:\n",
    "            y = split[1]\n",
    "        if id_rand == y:\n",
    "            id_rand = random.sample(range(1,10000),1)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        new_path = image_path+str(name)+\".\"+ str(id_rand)      \n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "        \n",
    "        for (x, y, w, h) in faces: \n",
    "            #cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            count+=1 \n",
    "            if not os.path.exists(new_path):\n",
    "                os.makedirs(new_path)\n",
    "            cv2.imwrite(new_path+\"/\"+str(name)+\".\"+str(count)+ \".jpg\", gray[y:y+h, x:x+w])\n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            cv2.waitKey(100)\n",
    "            if count == 15:\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "            elif cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "                break\n",
    "\n",
    "        cv2.imshow('cam',frame)\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(path):\n",
    "    myList = os.listdir(path)\n",
    "    for line in myList:\n",
    "        Type = line.split(\".\")\n",
    "        split = os.path.splitext(line)\n",
    "        if len(Type) < 2:\n",
    "            id_ = random.sample(range(10001,100000),1)\n",
    "            src=path+line\n",
    "            dst=path+Type[0]+'.'+str(id_)\n",
    "            os.rename(src,dst)\n",
    "        else:\n",
    "            id = Type[1]\n",
    "            name = Type[0]\n",
    "            id = split[1]\n",
    "            \n",
    "    recognizer = cv2.face.LBPHFaceRecognizer_create() \n",
    "    faceCascade = cv2.CascadeClassifier(\"data/haarcascade/haarcascade_frontalface_alt.xml\")\n",
    " \n",
    "    baseDir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "    #train the images under the images folder\n",
    "    imageDir = os.path.join(baseDir, path)\n",
    "    xTrain = []\n",
    "    yLabels = []\n",
    "    currentId = 1\n",
    "    labelIds = {}\n",
    "    \n",
    "    for root, dirs, files in os.walk(imageDir):\n",
    "        for file in files:\n",
    "            if file.endswith(\"png\") or file.endswith(\"jpg\"):                \n",
    "                label = os.path.basename(root)\n",
    "                if not label in labelIds:\n",
    "                    labelIds[label] = currentId\n",
    "                    currentId += 1\n",
    "                id_ = labelIds[label]\n",
    "                \n",
    "                path = os.path.join(root, file)\n",
    "                pilImage = PIL.Image.open(path).convert(\"L\")\n",
    "                size = (160, 160)\n",
    "                fin_img = pilImage.resize(size, Image.ANTIALIAS)\n",
    "                imageArray = np.array(fin_img)\n",
    "                faces = faceCascade.detectMultiScale(imageArray, scaleFactor=1.1, minNeighbors=5)\n",
    "                \n",
    "                for (x, y, w, h) in faces:                    \n",
    "                    roi = imageArray[y:y+h, x:x+w]\n",
    "                    xTrain.append(roi)\n",
    "                    yLabels.append(id_)\n",
    "\n",
    "    xTrain = np.asarray(xTrain)\n",
    "    trainY = np.array(yLabels)\n",
    "    try:\n",
    "        print('\\033[1m' + str(xTrain.shape + trainY.shape))\n",
    "    except:\n",
    "        print('\\033[1m' + 'problem with shape')\n",
    "        \n",
    "    with open(\"data/pickles/labels_haar\", \"wb\") as f:\n",
    "        pickle.dump(labelIds, f)\n",
    "        f.close()\n",
    "    #recognizer.update(xTrain, trainY)\n",
    "    recognizer.train(xTrain, trainY)\n",
    "    recognizer.save(\"data/trainer/trainingdata_haar.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recognizer\n",
    "def recognizer_face():\n",
    "    with open('data/pickles/labels_haar', 'rb') as f:\n",
    "        dicti = pickle.load(f)\n",
    "        f.close()\n",
    "    # Initialize and start realtime video capture\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(3, 800) # set video widht\n",
    "    cap.set(4, 600)\n",
    "    # Define min window size to be recognized as a face\n",
    "    minW = 0.1*cap.get(3)\n",
    "    minH = 0.1*cap.get(4)\n",
    "    #class to detect objects in a video stream\n",
    "    faceCascade = cv2.CascadeClassifier(\"data/haarcascade/haarcascade_frontalface_alt.xml\")\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "    recognizer.read(\"data/trainer/trainingdata_haar.yml\")\n",
    "\n",
    "    #for frame in camera.capture_continuous(rawCapture, format=\"bgr\", use_video_port=True):\n",
    "    while True:\n",
    "        ret,frame = cap.read()   \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        faces = faceCascade.detectMultiScale(gray, scaleFactor = 1.5, minNeighbors = 5)\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 185, 93), 2)\n",
    "            roiGray = gray[y:y+h, x:x+w]\n",
    "            \n",
    "            id_, conf  = recognizer.predict(roiGray)\n",
    "            for name, value in dicti.items():\n",
    "                if value == id_:\n",
    "                    #print(name)\n",
    "                    Typ = name.split(\".\")\n",
    "                    only_name = Typ[0]\n",
    "                    last = ''\n",
    "                    if only_name != last :\n",
    "                        last = only_name                \n",
    "            \n",
    "            speak=win.Dispatch(\"SAPI.spVoice\")\n",
    "            speak.rate=-1\n",
    "            color = (127,63,0)\n",
    "            if conf >= 40:\n",
    "                #cv2.putText(frame, only_name+'/'+str(\"{:.2f}\".format(conf)), (x, y), font, 0.5,color,1,cv2.LINE_AA)\n",
    "                cv2.putText(frame,  only_name+'/'+str(\"{:.2f}\".format(conf)), (int(x+w+15), int(y-64)), font, 1, color, 2)\n",
    "                #connect face and text\n",
    "                cv2.line(frame,(x+w, y-64),(x+w-25, y-64),color,1)\n",
    "                cv2.line(frame,(int(x+w/2),y),(x+w-25,y-64),color,1)\n",
    "                \n",
    "            else:\n",
    "                text = 'Unkown'\n",
    "                #cv2.putText(frame, text+'/'+str(\"{:.2f}\".format(conf)), (x, y), font, 0.5,(255,255,255),1,cv2.LINE_AA)\n",
    "                cv2.putText(frame,  text, (int(x+w+15), int(y-64)), font, 1, color, 2)\n",
    "                #connect face and text\n",
    "                cv2.line(frame,(x+w, y-64),(x+w-25, y-64),color,1)\n",
    "                cv2.line(frame,(int(x+w/2),y),(x+w-25,y-64),color,1)\n",
    "                speak.speak(name)\n",
    "\n",
    "            with open('data/attendance/Attendance_haar.csv','r+') as f:\n",
    "                myDataList = f.readlines()\n",
    "                nameList = []\n",
    "                for line in myDataList:\n",
    "                    entry = line.split(',')\n",
    "                    nameList.append(entry[0])\n",
    "                if only_name not in nameList:\n",
    "                    now = datetime.now()\n",
    "                    dtString = now.strftime('%H:%M:%S')\n",
    "                    f.writelines(f'\\n{only_name},{dtString}')\n",
    "                    speak.speak(name)\n",
    "        cv2.imshow('frame', frame)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 13:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter user : adem\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m(36, 36)\n"
     ]
    }
   ],
   "source": [
    "path =\"data/images/\"\n",
    "def F_popup():\n",
    "    pop_up = tk.Tk()\n",
    "    pop_up.wm_title('Facial Recognition')\n",
    "    pop_up.geometry(\"700x100\")\n",
    "    b1 = ttk.Button(pop_up, text='Train model', command=lambda:[training(path)])\n",
    "    b1.pack(side='left',pady=10,fill='both', expand=True)\n",
    "    b2 = ttk.Button(pop_up, text='Facial recognition', command=recognizer_face)\n",
    "    b2.pack(side='left',pady=10,fill='both', expand=True)\n",
    "    b3 = ttk.Button(pop_up, text='Close', command=pop_up.destroy)\n",
    "    b3.pack(side='right', pady=10,fill='both', expand=True)\n",
    "    pop_up.mainloop()\n",
    "    \n",
    "pop_up = tk.Tk()\n",
    "pop_up.wm_title('Facial Recognition')\n",
    "pop_up.geometry(\"500x100\")\n",
    "b1 = ttk.Button(pop_up, text='New users', command=new_user)\n",
    "b1.pack(side='left',pady=10,fill='both', expand=True)\n",
    "b2 = ttk.Button(pop_up, text='continue', command = lambda:[pop_up.destroy(),F_popup()])\n",
    "b2.pack(side='right', pady=10,fill='both', expand=True)\n",
    "pop_up.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('data/Attendance_haar.csv','w+') as f:\n",
    "    #pass  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
