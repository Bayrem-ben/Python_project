{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.patches import Circle\n",
    "from PIL import Image \n",
    "from numpy import savez_compressed\n",
    "from numpy import asarray\n",
    "from os import listdir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.4.0\n",
      "Keras Version: 2.4.0\n",
      "\n",
      "Python 3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]\n",
      "Pandas 1.2.0\n",
      "Scikit-Learn 0.24.0\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "import sys\n",
    "\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m(63, 160, 160, 63) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from numpy import savez_compressed\n",
    "from numpy import asarray\n",
    "import os\n",
    "from os import listdir\n",
    "import PIL.Image\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "\"\"\"\n",
    "def shape_to_np(shape, dtype=\"int\"):\n",
    "    coords = np.zeros((68, 2), dtype=dtype)\n",
    "    for i in range(0, 68):\n",
    "        coords[i] = (shape.part(i).x, shape.part(i).y)\n",
    "    return coords\n",
    "\"\"\"\n",
    "# extract face\n",
    "def extract_eye(filename):\n",
    "    eye_classifier = cv2.CascadeClassifier('./data/haarcascade_eye.xml')\n",
    "    face_cascade = cv2.CascadeClassifier(\"./data/haarcascade_frontalface_default.xml\")\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"data/shape_predictor_68_face_landmarks.dat\")\n",
    "    eyes_ex = []\n",
    "    # load image from file\n",
    "    image = Image.open(filename)\n",
    "    # convert to RGB, if needed\n",
    "    image = image.convert('L')\n",
    "    # convert to array\n",
    "    pixels = asarray(image)\n",
    "    faces = detector(pixels)\n",
    "    if faces is True :  \n",
    "        for face in faces:\n",
    "        #for k, d in enumerate(face):\n",
    "            landmarks = predictor(pixels, face)\n",
    "            shape = face_utils.shape_to_np(landmarks)\n",
    "            for x, y in shape [36:47]:\n",
    "\n",
    "            #eye_ratio = shape [36, 37, 38, 39, 40, 41,42, 43, 44, 45, 46, 47]\n",
    "                image = Image.fromarray(shape)\n",
    "                image = image.resize((160, 160))\n",
    "    else :\n",
    "        image = Image.fromarray(pixels)\n",
    "        image = image.resize((160, 160))\n",
    "    face_array = asarray(image)\n",
    "    return face_array\n",
    "\n",
    "def load_dataset(path):    \n",
    "    baseDir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "    #train the images under the images folder\n",
    "    imageDir = os.path.join(baseDir, path)\n",
    "    xTrain = []\n",
    "    yLabels = []\n",
    "    #count = []\n",
    "    #eye_imgs = []\n",
    "\n",
    "    currentId = 1\n",
    "    labelIds = {}\n",
    "    for root, dirs, files in os.walk(imageDir):\n",
    "        for file in files:\n",
    "            if file.endswith(\"png\") or file.endswith(\"jpg\") or file.endswith(\"jpeg\"): \n",
    "                path = os.path.join(root, file)\n",
    "                eye_imgs = extract_eye(path)\n",
    "                #create labels  \n",
    "                label = os.path.basename(root)\n",
    "                if not label in labelIds:\n",
    "                    labelIds[label] = currentId\n",
    "                    currentId += 1\n",
    "                id_ = labelIds[label]  \n",
    "                #count = [file for _ in range(len(eye_imgs))]  \n",
    "                #yLabels.append(count)    \n",
    "                xTrain.append(eye_imgs)\n",
    "                yLabels.append(id_)\n",
    "            #x.extend(faces)\n",
    "            #y.extend(labels)\n",
    "    trainX = np.asarray(xTrain) \n",
    "    trainY = np.array(yLabels)\n",
    "    #compress the data\n",
    "    #savez_compressed('data/trainer/facenet-mtcnn-dataset.npz',trainX,trainY) \n",
    "    try:\n",
    "        print('\\033[1m' + str(trainX.shape +trainY.shape)+' \\n')\n",
    "    except:\n",
    "        print('\\033[1m' + 'problem with shape')\n",
    "    return trainX, trainY\n",
    "\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create() \n",
    "trainx, trainy = load_dataset('data/open')\n",
    "#testx, testy = load_dataset('data/test')\n",
    "#compress the data\n",
    "#savez_compressed('data/training/deeplearning_eyes.npz',trainx,trainy, testx, testy)\n",
    "#recognizer.update(trainx, trainy)\n",
    "recognizer.train(trainx, trainy)\n",
    "recognizer.save(\"data/training/deeplearning_eyes_.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 160)\n",
      "109.59892545039328\n"
     ]
    }
   ],
   "source": [
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read(\"data/training/deeplearning_eyes_.yml\")\n",
    "\n",
    "\n",
    "baseDir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "#train the images under the images folder\n",
    "imageDir = os.path.join(baseDir, 'data/test')\n",
    "for root, dirs, files in os.walk(imageDir):\n",
    "    for file in files:\n",
    "        if file.endswith(\"png\") or file.endswith(\"jpg\") or file.endswith(\"jpeg\"): \n",
    "            path = os.path.join(root, file)\n",
    "            roi = extract_eye(path)\n",
    "print(roi.shape)    \n",
    "id_, conf  = recognizer.predict(roi)\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: train=63, test=1\n",
      "Loaded:  (63, 10) (63,) / (1, 10) (1,)\n",
      "[0.01520107 0.01796826 0.01710314 0.0159815  0.01450112 0.01476978\n",
      " 0.01457743 0.01417055 0.01613276 0.01698764 0.01916619 0.01474743\n",
      " 0.01554693 0.01654586 0.0151781  0.01630154 0.01433747 0.01633088\n",
      " 0.01751217 0.0150463  0.01523544 0.01636664 0.01438109 0.01537995\n",
      " 0.01704995 0.01541291 0.01563481 0.01526025 0.01507031 0.0154879\n",
      " 0.01565571 0.01890042 0.01607856 0.01583595 0.01712602 0.01494016\n",
      " 0.01542798 0.01582031 0.01622677 0.01584377 0.01534595 0.01547583\n",
      " 0.01497225 0.01617471 0.01994741 0.01629537 0.01674254 0.01487934\n",
      " 0.01512746 0.01557103 0.0149263  0.01567809 0.01753721 0.01433547\n",
      " 0.01767028 0.01516204 0.01546257 0.01498252 0.01605373 0.01489326\n",
      " 0.01665823 0.01536961 0.01549779] 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#### recog\n",
    "from numpy import load\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read(\"data/training/deeplearning_eyes_.yml\")\n",
    "# load dataset\n",
    "data = load('data/training/deeplearning_eyes_embeddings.npz')\n",
    "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "print('Dataset: train=%d, test=%d' % (trainX.shape[0], testX.shape[0]))\n",
    "print('Loaded: ', trainX.shape, trainy.shape,'/',testX.shape, testy.shape)\n",
    "\n",
    "\n",
    "#normalize the input data\n",
    "in_encode = Normalizer(norm='l2')\n",
    "trainx = in_encode.transform(trainX)\n",
    "new_testx = in_encode.transform(testX)\n",
    "\n",
    "#create a label vector\n",
    "new_testy = trainy \n",
    "out_encode = LabelEncoder()\n",
    "out_encode.fit(trainy)\n",
    "trainy = out_encode.transform(trainy)\n",
    "new_testy = out_encode.transform(new_testy)\n",
    "\n",
    "#define svm classifier model \n",
    "model =SVC(kernel='linear', probability=True)\n",
    "model.fit(trainx,trainy)\n",
    "\n",
    "#predict\n",
    "predict_train = model.predict(trainx)\n",
    "predict_test = model.predict(new_testx)\n",
    "\n",
    "#get the confidence score\n",
    "probability = model.predict_proba(new_testx)\n",
    "confidence = max(probability[0])\n",
    "\n",
    "#Accuracy\n",
    "acc_train = accuracy_score(trainy,predict_train)\n",
    "\n",
    "predict_test = out_encode.inverse_transform(predict_test)\n",
    "trainy = out_encode.inverse_transform(trainy)\n",
    "\n",
    "print(probability[0], acc_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image # For face recognition we will the the LBPH Face Recognizer\n",
    "import pickle\n",
    "import dlib\n",
    "from tkinter import *\n",
    "from tkinter import ttk  \n",
    "import tkinter as tk\n",
    "import tkinter.messagebox\n",
    "from PIL import Image\n",
    "\n",
    "#recognizer\n",
    "def recognizer_face():\n",
    "\n",
    "    # Initialize and start realtime video capture\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(3, 800) # set video widht\n",
    "    cap.set(4, 600)\n",
    "\n",
    "    #class to detect objects in a video stream\n",
    "    face_cascade = cv2.CascadeClassifier(\"./data/haarcascade_frontalface_default.xml\")\n",
    "    eye_classifier = cv2.CascadeClassifier('./data/haarcascade_eye.xml')\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "    recognizer.read(\"data/training/deeplearning_eyes_.yml\")\n",
    "\n",
    "    #for frame in camera.capture_continuous(rawCapture, format=\"bgr\", use_video_port=True):\n",
    "    while True:\n",
    "        ret,frame = cap.read()   \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "        eyes = eye_classifier.detectMultiScale(gray, scaleFactor = 1.5, minNeighbors = 5)\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 185, 93), 2)\n",
    "            roiGray = gray[y:y+h, x:x+w]\n",
    "            \n",
    "            id_, conf  = recognizer.predict(roiGray)              \n",
    "            \n",
    "            color = (127,63,0)\n",
    "            if conf >= 40:\n",
    "                #cv2.putText(frame, only_name+'/'+str(\"{:.2f}\".format(conf)), (x, y), font, 0.5,color,1,cv2.LINE_AA)\n",
    "                cv2.putText(frame,  'sleeping'+'/'+str(\"{:.2f}\".format(conf)), (int(x+w+15), int(y-64)), font, 1, color, 2)\n",
    "                #connect face and text\n",
    "                cv2.line(frame,(x+w, y-64),(x+w-25, y-64),color,1)\n",
    "                cv2.line(frame,(int(x+w/2),y),(x+w-25,y-64),color,1)\n",
    "            else:\n",
    "                text = 'Unkown'\n",
    "                #cv2.putText(frame, text+'/'+str(\"{:.2f}\".format(conf)), (x, y), font, 0.5,(255,255,255),1,cv2.LINE_AA)\n",
    "                cv2.putText(frame,  text, (int(x+w+15), int(y-64)), font, 1, color, 2)\n",
    "                #connect face and text\n",
    "                cv2.line(frame,(x+w, y-64),(x+w-25, y-64),color,1)\n",
    "                cv2.line(frame,(int(x+w/2),y),(x+w-25,y-64),color,1)\n",
    "\n",
    "            with open('data/Attendance.csv','w') as f:\n",
    "                now = datetime.now()\n",
    "                dtString = now.strftime('%H:%M:%S')\n",
    "                f.writelines(f'\\n{conf},{dtString}')\n",
    "                    \n",
    "        cv2.imshow('frame', frame)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 13:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()  \n",
    "    \n",
    "recognizer_face()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: train=357, test=7\n",
      "Loaded:  (357, 10) (357,) / (7, 10) (7,)\n",
      "[0.00759112 0.00870231 0.01137163 0.0113514  0.0145917  0.00763525\n",
      " 0.00921942 0.01146311 0.00806243 0.00738459 0.01487994 0.01594686\n",
      " 0.0147933  0.00801223 0.0138212  0.01449929 0.01636489 0.00850058\n",
      " 0.03361082 0.01208208 0.01839601 0.00479535 0.00509219 0.01324462\n",
      " 0.02435852 0.00742749 0.01824333 0.02900738 0.01331823 0.0070356\n",
      " 0.00545537 0.02144021 0.00550171 0.00509131 0.02597418 0.02087834\n",
      " 0.01096688 0.00573964 0.01325523 0.01716281 0.01147268 0.01061777\n",
      " 0.01080897 0.01065487 0.01463342 0.0154387  0.01249193 0.00651014\n",
      " 0.01126175 0.00989362 0.02489639 0.01078258 0.02782452 0.00787417\n",
      " 0.00865098 0.00730543 0.0057816  0.00744782 0.01236611 0.00878307\n",
      " 0.01581372 0.0048767  0.008378   0.00740873 0.00813051 0.00748616\n",
      " 0.00595684 0.00762424 0.01195363 0.0048871  0.00876329 0.00951402\n",
      " 0.00598681 0.00803843 0.01377426 0.00678233 0.0096645  0.00933842\n",
      " 0.00725449 0.00480015 0.01005797 0.01356009 0.00560766 0.00524226\n",
      " 0.00664513 0.01193733 0.00627719 0.00859875 0.00787616] 0.047619047619047616\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#### recog\n",
    "from numpy import load\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "# load dataset\n",
    "data = load('data/training/deeplearning_eyes_embeddings.npz')\n",
    "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "print('Dataset: train=%d, test=%d' % (trainX.shape[0], testX.shape[0]))\n",
    "print('Loaded: ', trainX.shape, trainy.shape,'/',testX.shape, testy.shape)\n",
    "\n",
    "\n",
    "#normalize the input data\n",
    "in_encode = Normalizer(norm='l2')\n",
    "trainx = in_encode.transform(trainX)\n",
    "new_testx = in_encode.transform(testX)\n",
    "\n",
    "#create a label vector\n",
    "new_testy = trainy \n",
    "out_encode = LabelEncoder()\n",
    "out_encode.fit(trainy)\n",
    "trainy = out_encode.transform(trainy)\n",
    "new_testy = out_encode.transform(new_testy)\n",
    "\n",
    "#define svm classifier model \n",
    "model =SVC(kernel='linear', probability=True)\n",
    "model.fit(trainx,trainy)\n",
    "\n",
    "#predict\n",
    "predict_train = model.predict(trainx)\n",
    "predict_test = model.predict(new_testx)\n",
    "\n",
    "#get the confidence score\n",
    "probability = model.predict_proba(new_testx)\n",
    "confidence = max(probability[0])\n",
    "\n",
    "#Accuracy\n",
    "acc_train = accuracy_score(trainy,predict_train)\n",
    "\n",
    "predict_test = out_encode.inverse_transform(predict_test)\n",
    "trainy = out_encode.inverse_transform(trainy)\n",
    "\n",
    "print(probability[0], acc_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('data/Attendance_deep.csv','w+') as f:\n",
    "    #pass  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
