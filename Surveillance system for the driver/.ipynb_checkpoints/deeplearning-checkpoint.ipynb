{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.patches import Circle\n",
    "from PIL import Image \n",
    "from numpy import savez_compressed\n",
    "from numpy import asarray\n",
    "from os import listdir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier('./data/haarcascade_frontalface_default.xml')\n",
    "eye_classifier = cv2.CascadeClassifier('./data/haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from numpy import savez_compressed\n",
    "from numpy import asarray\n",
    "import os\n",
    "from os import listdir\n",
    "import PIL.Image\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "\n",
    "# extract face\n",
    "def extract_eye(filename):\n",
    "    eye_classifier = cv2.CascadeClassifier('./data/haarcascade_eye.xml')\n",
    "    face_cascade = cv2.CascadeClassifier(\"./data/haarcascade_frontalface_default.xml\")\n",
    "    # Initializing the face detector and facial landmark predictor \n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"data/shape_predictor_68_face_landmarks.dat\")\n",
    "    eyes_ex = []\n",
    "    # load image from file\n",
    "    image = Image.open(filename)\n",
    "    # convert to RGB, if needed\n",
    "    image = image.convert('RGB')\n",
    "    # convert to array\n",
    "    pixels = asarray(image)\n",
    "    faces = detector(pixels)\n",
    "    if faces is True :  \n",
    "        for face in faces:\n",
    "        #for k, d in enumerate(face):\n",
    "            landmarks = predictor(pixels, face)\n",
    "            shape = face_utils.shape_to_np(landmarks)\n",
    "            for x, y in shape [36:47]:\n",
    "            #eye_ratio = shape [36, 37, 38, 39, 40, 41,42, 43, 44, 45, 46, 47]\n",
    "                image = Image.fromarray(shape)\n",
    "                image = image.resize((224, 224))\n",
    "    else :\n",
    "        image = Image.fromarray(pixels)\n",
    "        image = image.resize((224, 224))\n",
    "    face_array = asarray(image)\n",
    "    return face_array\n",
    "\n",
    "def load_dataset(path):    \n",
    "    baseDir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "    #train the images under the images folder\n",
    "    imageDir = os.path.join(baseDir, path)\n",
    "    xTrain = []\n",
    "    yLabels = []\n",
    "    #count = []\n",
    "    #eye_imgs = []\n",
    "\n",
    "    currentId = 1\n",
    "    labelIds = {}\n",
    "    for root, dirs, files in os.walk(imageDir):\n",
    "        for file in files:\n",
    "            if file.endswith(\"png\") or file.endswith(\"jpg\") or file.endswith(\"jpeg\"): \n",
    "                path = os.path.join(root, file)\n",
    "                eye_imgs = extract_eye(path)\n",
    "                #create labels  \n",
    "                label = os.path.basename(root)\n",
    "                if not label in labelIds:\n",
    "                    labelIds[label] = currentId\n",
    "                    currentId += 1\n",
    "                id_ = labelIds[label]  \n",
    "                count = [file for _ in range(len(eye_imgs))]  \n",
    "                #yLabels.append(count)    \n",
    "                #xTrain.append(eye_imgs)\n",
    "                #yLabels.append(id_)\n",
    "                xTrain.extend(eye_imgs)\n",
    "                yLabels.extend(count)\n",
    "    trainX = np.asarray(xTrain) \n",
    "    trainY = np.array(yLabels)\n",
    "    #compress the data\n",
    "    #savez_compressed('data/trainer/facenet-mtcnn-dataset.npz',trainX,trainY) \n",
    "    try:\n",
    "        print('\\033[1m' + str(trainX.shape +trainY.shape)+' \\n')\n",
    "    except:\n",
    "        print('\\033[1m' + 'problem with shape')\n",
    "    return trainX, trainY\n",
    "\n",
    "    \n",
    "trainx, trainy = load_dataset('data/eyes')\n",
    "testx, testy = load_dataset('data/test')\n",
    "#compress the data\n",
    "savez_compressed('data/training/deeplearning_eyes.npz',trainx,trainy, testx, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 2 classes.\n",
      "Found 0 images belonging to 2 classes.\n",
      "Found 0 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "import PIL.Image\n",
    "from numpy import load\n",
    "from numpy import expand_dims\n",
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    "from keras.models import load_model\n",
    "from keras.layers import Flatten\n",
    "import keras\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model, Sequential\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from keras.layers import Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Conv2D,Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory='data/eyes', target_size=(224,224), classes=['eyes open', 'eyes closed'],batch_size=5) #,batch_size=10\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory='data/new', target_size=(224,224), classes=['eyes open', 'eyes closed'],batch_size=5)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory='data/test', target_size=(224,224), classes=['eyes open', 'eyes closed'],batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding\n",
    "from numpy import load\n",
    "from numpy import expand_dims\n",
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    "from keras.models import load_model\n",
    "from keras.layers import Flatten\n",
    "import keras\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model, Sequential\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from keras.layers import Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Conv2D,Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "vgg16_model = tf.keras.applications.vgg16.VGG16()\n",
    "#vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "for layer in vgg16_model.layers[:-1]:\n",
    "    model.add(layer)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "model.add(keras.layers.Dense(units = 2, activation =\"softmax\"))\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded:  (100, 224, 224, 3) (100,) / (4, 224, 224, 3) (4,)\n",
      "Loaded Model\n",
      "(100, 2)\n",
      "(4, 2)\n"
     ]
    }
   ],
   "source": [
    "#embedding\n",
    "from numpy import load\n",
    "from numpy import expand_dims\n",
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    "from keras.models import load_model\n",
    "from keras.layers import Flatten\n",
    "import keras\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model, Sequential\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from keras.layers import Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Conv2D,Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras_facenet import FaceNet\n",
    "\n",
    "# get the face embedding for one face\n",
    "def get_embedding(model, face_pixels):\n",
    "    # scale pixel values\n",
    "    face_pixels = face_pixels.astype('float32')\n",
    "    # standardize pixel values across channels (global)\n",
    "    mean, std = face_pixels.mean(), face_pixels.std()\n",
    "    face_pixels = (face_pixels - mean) / std\n",
    "    # transform face into one sample\n",
    "    samples = expand_dims(face_pixels, axis=0)\n",
    "    # make prediction to get embedding\n",
    "    yhat = model.predict(samples)\n",
    "    return yhat[0]\n",
    " \n",
    "# load the face dataset\n",
    "data = load('data/training/deeplearning_eyes.npz',allow_pickle=True)\n",
    "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "print('Loaded: ', trainX.shape, trainy.shape,'/',testX.shape, testy.shape)\n",
    "\n",
    "######################## model\n",
    "\n",
    "vgg16_model = tf.keras.applications.vgg16.VGG16()\n",
    "model = keras.Sequential()\n",
    "for layer in vgg16_model.layers[:-1]:\n",
    "    model.add(layer)\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "model.add(keras.layers.Dense(units = 2, activation =\"softmax\"))\n",
    "model.compile(keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#model = load_model('facenet_keras.h5')\n",
    "print('Loaded Model')\n",
    "\n",
    "#################################\n",
    "# convert each face in the train set to an embedding\n",
    "newTrainX = list()\n",
    "for face_pixels in trainX:\n",
    "    embedding = get_embedding(model, face_pixels)\n",
    "    newTrainX.append(embedding)\n",
    "newTrainX = asarray(newTrainX)\n",
    "print(newTrainX.shape)\n",
    "\n",
    "# convert each face in the test set to an embedding\n",
    "newTestX = list()\n",
    "for face_pixels in testX:\n",
    "    embedding = get_embedding(model, face_pixels)\n",
    "    newTestX.append(embedding)\n",
    "newTestX = asarray(newTestX)\n",
    "print(newTestX.shape)\n",
    "\n",
    "# save arrays to one file in compressed format\n",
    "savez_compressed('data/training/deeplearning_eyes_embeddings.npz', newTrainX, trainy, newTestX, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: train=100, test=4\n",
      "Loaded:  (100, 2) (100,) / (4, 2) (4,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-1ddd90a89852>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loaded: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtestX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtesty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mnsamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mny\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mtrainx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnsamples\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mny\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mnsamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mny\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "#recognize\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "data = load('data/training/deeplearning_eyes_embeddings.npz', allow_pickle=True)\n",
    "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "print('Dataset: train=%d, test=%d' % (trainX.shape[0], testX.shape[0]))\n",
    "print('Loaded: ', trainX.shape, trainy.shape,'/',testX.shape, testy.shape)\n",
    "\n",
    "nsamples, nx, ny = trainX.shape\n",
    "trainx = trainX.reshape((nsamples*nx,ny))\n",
    "nsamples, nx, ny = testX.shape\n",
    "testx = testX.reshape((nsamples*nx,ny))\n",
    "# fit model\n",
    "model.fit(x= trainx, validation_data= testx, epochs = 5, verbose = 2)\n",
    "\n",
    "# predict\n",
    "yhat_train = model.predict(trainX)\n",
    "yhat_test = model.predict(testX)\n",
    "# score\n",
    "score_train = accuracy_score(trainy, yhat_train)\n",
    "score_test = accuracy_score(testy, yhat_test)\n",
    "\n",
    "#get the confidence score\n",
    "probability = model.predict_proba(yhat_test)\n",
    "confidence = max(probability)\n",
    "#Accuracy\n",
    "acc_train = accuracy_score(trainy,predict_train)\n",
    "\n",
    "# summarize\n",
    "print('Accuracy: train=%.3f, test=%.3f' % (score_train*100, score_test*100))\n",
    "print(confidence)\n",
    "print(acc_train)\n",
    "\"\"\"\n",
    "param_grid = {'n_neighbors': np.arange(1, 20),\n",
    "              'metric': ['euclidean', 'manhattan']}\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5)\n",
    "grid.fit(trainx, trainy)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "model = grid.best_estimator_\n",
    "a = model.score(testX, testy)\n",
    "print(a)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: train=100, test=4\n",
      "Loaded:  (100, 2) (100,) / (4, 2) (4,)\n",
      "(80, 2) (20, 2)\n",
      "(80,) (20,)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "If no scoring is specified, the estimator passed should have a 'score' method. The estimator <tensorflow.python.keras.engine.sequential.Sequential object at 0x00000247D0203FD0> does not.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-bbc9a7e26326>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m N, train_score, val_score = learning_curve(model, trainX, trainy,\n\u001b[0m\u001b[0;32m     28\u001b[0m                                            train_sizes=np.linspace(0.1, 1, 10), cv=2)\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mlearning_curve\u001b[1;34m(estimator, X, y, groups, train_sizes, cv, scoring, exploit_incremental_learning, n_jobs, pre_dispatch, verbose, shuffle, random_state, error_score, return_times, fit_params)\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[0mcv_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1362\u001b[1;33m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[0mn_max_training_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv_iter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[1;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[0;32m    448\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 450\u001b[1;33m             raise TypeError(\n\u001b[0m\u001b[0;32m    451\u001b[0m                 \u001b[1;34m\"If no scoring is specified, the estimator passed should \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m                 \u001b[1;34m\"have a 'score' method. The estimator %r does not.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: If no scoring is specified, the estimator passed should have a 'score' method. The estimator <tensorflow.python.keras.engine.sequential.Sequential object at 0x00000247D0203FD0> does not."
     ]
    }
   ],
   "source": [
    "# another test\n",
    "\n",
    "from numpy import load\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# load dataset\n",
    "data = load('data/training/deeplearning_eyes_embeddings.npz')\n",
    "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "print('Dataset: train=%d, test=%d' % (trainX.shape[0], testX.shape[0]))\n",
    "print('Loaded: ', trainX.shape, trainy.shape,'/',testX.shape, testy.shape)\n",
    "\n",
    "x_train, y_train, x_test, y_test = train_test_split(trainX, trainy, test_size = 0.2, random_state = 5)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "N, train_score, val_score = learning_curve(model, trainX, trainy,\n",
    "                                           train_sizes=np.linspace(0.1, 1, 10), cv=2)\n",
    "\n",
    "print(N)\n",
    "plt.plot(N, train_score.mean(axis=1), label='train')\n",
    "plt.plot(N, val_score.mean(axis=1), label='validation')\n",
    "plt.xlabel('train_sizes')\n",
    "plt.legend()\n",
    "\n",
    "#print(model.score(trainX, trainy))\n",
    "#print(model.score(testX, testy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recognizer real live\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw \n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from numpy import array\n",
    "from numpy import expand_dims\n",
    "from numpy import reshape\n",
    "from numpy import load\n",
    "from numpy import max\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Conv2D,Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "def get_embedding(model, face_pixels):\n",
    "    # scale pixel values\n",
    "    face_pixels = face_pixels.astype('float32')\n",
    "    # standardize pixel values across channels (global)\n",
    "    mean, std = face_pixels.mean(), face_pixels.std()\n",
    "    face_pixels = (face_pixels - mean) / std\n",
    "    # transform face into one sample\n",
    "    samples = expand_dims(face_pixels, axis=0)\n",
    "    # make prediction to get embedding\n",
    "    yhat = model.predict(samples)\n",
    "    return yhat[0]\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "eye_classifier = cv2.CascadeClassifier('./data/haarcascade_eye.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "#cap.set(3, 1024) # set video widht\n",
    "#cap.set(4, 720)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(32, input_shape=(160,160)),\n",
    "        Flatten(),\n",
    "        Activation('sigmoid'),\n",
    "        Dense(output_dim=10)])\n",
    "    \n",
    "    img1 = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    pixels = np.asarray(img1)\n",
    "    eyes = eye_classifier.detectMultiScale(pixels)\n",
    "    for (ex,ey,ew,eh) in eyes: \n",
    "        cv2.rectangle(frame,(ex,ey),(ex+ew,ey+eh),(255,0,0),1)\n",
    "        store_face = pixels[ey:ey+eh,ex:ex+ew]\n",
    "        image1 = Image.fromarray(store_face,'L')\n",
    "        store_f = image1.resize((160,160), Image.ANTIALIAS)\n",
    "        face_array = np.asarray(store_f)\n",
    "        #face_array = face_array.reshape(-1,160,160,3)     \n",
    "        face_array = np.expand_dims(face_array, axis = 0)\n",
    "        \n",
    "        #new_testx = list()\n",
    "        #embedding = get_embedding(model, face_array)\n",
    "        #new_testx.append(embedding)\n",
    "        #new_testx = asarray(new_testx)        \n",
    "        new_testx = list()\n",
    "        for face_pixels in trainX:\n",
    "            embedding = get_embedding(model, face_pixels)\n",
    "            new_testx.append(embedding)\n",
    "        new_testx = asarray(new_testx)\n",
    "        \n",
    "        data1 = load('data/training/deeplearning_eyes.npz')\n",
    "        train_x,train_y, test_x, testx_y = data1['arr_0'], data1['arr_1'], data1['arr_2'], data1['arr_3']\n",
    "\n",
    "        data = load('data/training/deeplearning_eyes_embeddings.npz')\n",
    "        trainx,trainy, testx, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "        #print(\"Loaded data: Train=%d , Test=%d\"%(trainx.shape[0],new_testx.shape[0]))      \n",
    "        \n",
    "        print(trainx.shape, new_testx.shape)\n",
    "        nsamples, nx, ny = trainx.shape\n",
    "        my_train_x = trainx.reshape((nsamples,nx*ny))\n",
    "        #nsamples, nx, ny = new_testx.shape\n",
    "        #new_test_x = new_testx.reshape((nsamples,nx*ny))\n",
    "        print(my_train_x.shape, new_testx.shape)\n",
    "\n",
    "        #normalize the input data\n",
    "        in_encode = Normalizer(norm='l2')\n",
    "        trainx = in_encode.transform(my_train_x)\n",
    "        new_testx = in_encode.transform(new_testx)\n",
    "\n",
    "        #create a label vector\n",
    "        new_testy = trainy \n",
    "        out_encode = LabelEncoder()\n",
    "        out_encode.fit(trainy)\n",
    "        trainy = out_encode.transform(trainy)\n",
    "        new_testy = out_encode.transform(new_testy)\n",
    "\n",
    "        #define svm classifier model \n",
    "        model =SVC(kernel='linear', probability=True)\n",
    "        model.fit(trainx,trainy)\n",
    "\n",
    "        #predict\n",
    "        predict_train = model.predict(trainx)\n",
    "        predict_test = model.predict(new_testx)\n",
    "\n",
    "        #get the confidence score\n",
    "        probability = model.predict_proba(new_testx)\n",
    "        confidence = max(probability)\n",
    "\n",
    "        #Accuracy\n",
    "        acc_train = accuracy_score(trainy,predict_train)\n",
    "\n",
    "        #display\n",
    "        trainy_list = list(trainy)\n",
    "        p=int(predict_test)\n",
    "        if p in trainy_list:\n",
    "            val = trainy_list.index(p)\n",
    "            \n",
    "        predict_test = out_encode.inverse_transform(predict_test)\n",
    "        #cv2.putText(frame, predict_test, (x, y), font, 0.5,(255,255,255),1,cv2.LINE_AA)\n",
    "        #cv2.putText(frame, train_x[val], (x, y), font, 0.5,(255,255,255),1,cv2.LINE_AA)\n",
    "        trainy = out_encode.inverse_transform(trainy)\n",
    "        #cv2.putText(frame, trainy[val], (x, y), font, 0.5,(255,255,255),1,cv2.LINE_AA)\n",
    "        \n",
    "        print(confidence)\n",
    "        \n",
    "        color = (127,63,0)\n",
    "        cv2.putText(frame, str(\"{:.2f}\".format(confidence)), (int(x+w+15), int(y-64)), font, 1, color, 2)\n",
    "        #cv2.putText(frame,  name, (x, y), font, 1, color, 2)\n",
    "        #connect face and text\n",
    "        cv2.line(frame,(x+w, y-64),(x+w-25, y-64),color,1)\n",
    "        cv2.line(frame,(int(x+w/2),y),(x+w-25,y-64),color,1)\n",
    "        \n",
    "    cv2.imshow('cam', frame)\n",
    "    #plt.imshow(frame)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 13:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('data/Attendance_deep.csv','w+') as f:\n",
    "    #pass  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
